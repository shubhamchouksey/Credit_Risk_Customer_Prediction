{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Models\n",
    "\n",
    "In this lab you will work with **naive Bayes models**. Naive Bayes models are a surprisingly useful and effective simplification of the general Bayesian models. Naive Bayes models make the naive assumption of statistical independence of the features. In many cases, naive Bayes module are surprisingly effective despite violating the assumption of independence. \n",
    "\n",
    "In simple terms, naive Bayes models use empirical distributions of the features to compute probabilities of the labels. The naive Bayes models can use most any family of distributions for the features. It is important to select the correct distribution family for the data you are working with. Common cases are:\n",
    "- **Gaussian;** for continuous or numerical features.\n",
    "- **Bernoulli;** for features with binary values. \n",
    "- **Multinomial;** for features with more than two categories. \n",
    "\n",
    "These is one pit fall, the model fails if a zero probability is encountered. This situation occurs when there is a 'hole' in the sample space where there are no samples. A simple smoothing procedure can deal with this problem. The smoothing hyperparameter, usually called alpha, is one of the few required for naive Bayes models. \n",
    "\n",
    "Some properties of naive Bayes models are:\n",
    "- Computational complexity is linear in number of parameter/features, making naive Bayes models highly scalable. There are out or core approaches suitable for massive datasets.\n",
    "- Requires minimal data to produce models that generalizes well. If there are only a few cases per category to train a model a naive Bayes model can be a good choice. \n",
    "- Have a simple and inherent regularization.\n",
    "\n",
    "Naive Bayes models are used in many situations including:\n",
    "\n",
    "- Document classification\n",
    "- SPAM detection\n",
    "- Image classification \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: German Credit Dataset\n",
    "\n",
    "You will try a more complex example using the credit scoring data. You will use the prepared data which had the following preprocessing:\n",
    "1. Cleaning missing values.\n",
    "2. Aggregating categories of certain categorical variables. \n",
    "3. Encoding categorical variables as binary dummy variables.\n",
    "4. Standardizing numeric variables. \n",
    "\n",
    "As a first step, execute the code in the cell below to load the required packages to run the rest of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "#from statsmodels.api import datasets\n",
    "from sklearn import datasets ## Get dataset from sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code in the cell below to load the features and labels as numpy arrays for the example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 35)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "Features = np.array(pd.read_csv('Credit_Features.csv'))\n",
    "Labels = np.array(pd.read_csv('Credit_Labels.csv'))\n",
    "Labels = Labels.reshape(Labels.shape[0],)\n",
    "print(Features.shape)\n",
    "print(Labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Features array has both numeric features and binary features (dummy variables for the categorical features). Therefore, a Gaussian model must be used. However, this model is not ideal, since numeric features are mixed with features exhibiting Bernoulli distributions, the binary features. \n",
    "\n",
    "The code in the cell below does the following processing:\n",
    "1. Defines a 10 fold cross validation object. \n",
    "2. Defines a Gaussian naive Bayes model.\n",
    "3. Performs a 10 fold cross validation.\n",
    "4. Prints results from the cross validation. \n",
    "\n",
    "Execute this code and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.86486906 -0.933901    0.91847717  2.27100592  0.          1.\n",
      "   0.          0.          0.          1.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          1.          0.          0.          0.\n",
      "   0.          0.          1.          0.          0.          0.\n",
      "   1.          0.          0.          1.          0.        ]\n",
      " [ 1.7083687   1.16304581 -0.87018333 -1.44615223  1.          0.\n",
      "   0.          0.          0.          0.          1.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          1.          0.          0.          1.\n",
      "   0.          0.          0.          0.          1.          0.\n",
      "   0.          0.          0.          1.          0.        ]\n",
      " [-0.67378981 -0.1815588  -0.87018333  1.22669602  0.          0.\n",
      "   0.          1.          0.          1.          0.          0.\n",
      "   0.          0.          0.          0.          0.          1.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          1.          0.          0.          1.\n",
      "   0.          0.          0.          1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Features[:3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance metric = 0.691\n",
      "SDT of the metric       = 0.093\n",
      "Outcomes by cv fold\n",
      "Fold  1    0.720\n",
      "Fold  2    0.660\n",
      "Fold  3    0.770\n",
      "Fold  4    0.690\n",
      "Fold  5    0.750\n",
      "Fold  6    0.430\n",
      "Fold  7    0.690\n",
      "Fold  8    0.760\n",
      "Fold  9    0.710\n",
      "Fold 10    0.730\n"
     ]
    }
   ],
   "source": [
    "nr.seed(321)\n",
    "cv_folds = ms.KFold(n_splits=10, shuffle = True)\n",
    "    \n",
    "nr.seed(498)\n",
    "NB_credit = GaussianNB()\n",
    "cv_estimate = ms.cross_val_score(NB_credit, Features, Labels, \n",
    "                                 cv = cv_folds) # Use the outside folds\n",
    "\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance metric = 0.679\n",
      "SDT of the metric       = 0.106\n",
      "Outcomes by cv fold\n",
      "Fold  1    0.670\n",
      "Fold  2    0.390\n",
      "Fold  3    0.680\n",
      "Fold  4    0.710\n",
      "Fold  5    0.760\n",
      "Fold  6    0.770\n",
      "Fold  7    0.620\n",
      "Fold  8    0.760\n",
      "Fold  9    0.730\n",
      "Fold 10    0.700\n"
     ]
    }
   ],
   "source": [
    "nr.seed(498)\n",
    "NB_credit = GaussianNB()\n",
    "cv_estimate = ms.cross_val_score(NB_credit, Features, Labels, \n",
    "                                 cv = 10) # Use the outside folds\n",
    "\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these results. Notice that the standard deviation of the mean of the AUC is more than an order of magnitude smaller than the mean. This indicates that this model is likely to generalize well. \n",
    "\n",
    "Now, you will build and test a model using a single split of the dataset. As a first step, execute the code in the cell below to create training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly sample cases to create independent training and test data\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "X_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "X_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below defines a naive Bayes model object and then fits the model to the training data. Execute this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_credit_mod = GaussianNB() \n",
    "NB_credit_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the test data subset, the code in the cell below scores and prints evaluation metrics for the model. \n",
    "\n",
    "Execute this code, examine the results, and answer **Question 2** on the course page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive        30               182\n",
      "Actual negative         6                82\n",
      "\n",
      "Accuracy        0.37\n",
      "AUC             0.69\n",
      "Macro precision 0.57\n",
      "Macro recall    0.54\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      212            88\n",
      "Precision    0.83          0.31\n",
      "Recall       0.14          0.93\n",
      "F1           0.24          0.47\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = NB_credit_mod.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, these performance metrics are poor. Barely half the bad credit risk customers are correctly identified. The reported AUC is quite a bit better than the mean achieved with the 5 fold cross validation. It is likely these figures are optimistic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps, a Bernoulli naive Bayes model will work better. Since naive Bayes models tend to be less sensitive to the quantity of training data, this approach may be reasonable. To apply this model, the numeric features must be dropped from the array. Execute the code in the cell below to remove the numeric features and examine the resulting sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features = Features[:,4:]\n",
    "Features[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 1. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 1. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Features[:3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that all of the features are binary. A Bernoulli naive Bayes can now be applied to these features. \n",
    "\n",
    "10 fold nested cross validation is used to estimate the optimal hyperparameter and performs model selection for the naive Bayes model. Execute the code in the cell below to define inside and outside fold objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below estimates the best hyperparameters using 10 fold cross validation. There are two points to notice here:\n",
    "1. In this case, a grid for one hyperparameter: alpha is the smoothing parameter to avoid zero probabilities.  \n",
    "3. The model is fit on the grid and the best estimated hyperparameters are printed. \n",
    "\n",
    "Execute this code and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "nr.seed(3456)\n",
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "## Define the NB regression model\n",
    "NB_clf = BernoulliNB() \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "clf = ms.GridSearchCV(estimator = NB_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "clf.fit(Features, Labels)\n",
    "print(clf.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smallest alpha hyperparameter has been selected. This indicates that there is very little problem with zero probabilities in this problem. This situation results from the fact that the probability space sampled is dense. \n",
    "\n",
    "The code in the cell below executes the outer loop of the cross validation to estimate model performance with the optimal hyperparameter. Execute this code and examine the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance metric = 0.754\n",
      "SDT of the metric       = 0.040\n",
      "Outcomes by cv fold\n",
      "Fold  1    0.735\n",
      "Fold  2    0.701\n",
      "Fold  3    0.733\n",
      "Fold  4    0.745\n",
      "Fold  5    0.771\n",
      "Fold  6    0.757\n",
      "Fold  7    0.762\n",
      "Fold  8    0.857\n",
      "Fold  9    0.765\n",
      "Fold 10    0.713\n"
     ]
    }
   ],
   "source": [
    "#NB_credit = BernoulliNB(alpha = clf.best_estimator_.alpha)\n",
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(clf, Features, Labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first look, the AUC seems reasonable. The standard deviation is an order of magnitude less than the AUC. \n",
    "\n",
    "Next, sample the dataset into training and testing subsets by executing the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly sample cases to create independent training and test data\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "X_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "X_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the code below to fit and score the Bernoulli naive Bayes model and display the performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive       178                34\n",
      "Actual negative        34                54\n",
      "\n",
      "Accuracy        0.77\n",
      "AUC             0.78\n",
      "Macro precision 0.73\n",
      "Macro recall    0.73\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      212            88\n",
      "Precision    0.84          0.61\n",
      "Recall       0.84          0.61\n",
      "F1           0.84          0.61\n"
     ]
    }
   ],
   "source": [
    "NB_credit_mod = BernoulliNB(alpha = clf.best_estimator_.alpha) \n",
    "NB_credit_mod.fit(X_train, y_train)\n",
    "probabilities = NB_credit_mod.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for this Bernoulli naive Bayes model are much better than for the Gaussian model. Still, they could be better.\n",
    "\n",
    "The current model uses the empirical distribution of the label values for the prior value of $p$ of the Bernoulli distribution. This probability is invariably skewed toward the majority case. Since the bank cares more about the minority case, setting this distribution to a fixed prior value can help overcome the class imbalance. The code in the cell below redefines the model object with prior probability of 0.6 for the minority case. \n",
    "\n",
    "Execute this code, examine the results, and answer **Question 3** on the course page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive       116                96\n",
      "Actual negative        17                71\n",
      "\n",
      "Accuracy        0.62\n",
      "AUC             0.78\n",
      "Macro precision 0.65\n",
      "Macro recall    0.68\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      212            88\n",
      "Precision    0.87          0.43\n",
      "Recall       0.55          0.81\n",
      "F1           0.67          0.56\n"
     ]
    }
   ],
   "source": [
    "NB_credit_mod = BernoulliNB(alpha = clf.best_estimator_.alpha,\n",
    "                            class_prior = [0.4,0.6]) \n",
    "NB_credit_mod.fit(X_train, y_train)\n",
    "probabilities = NB_credit_mod.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of bad credit cases are now correctly identified. However, this characteristic is at the cost of a high false negative error rate. Still, given that the cost to the bank of a false negative is five times the cost of a false positive, this may be a good solution. An infinite number of other models are possible by changing the prior distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab you have accomplished the following:\n",
    "1. Used a Gaussian naive model to classify the cases of the iris data. The overall model performance was reasonable. \n",
    "2. Fit a Gaussian naive Bayes model on the bank credit data. The performance of this model was poor as a result of many Bernoulli distributed dummy features.\n",
    "3. Used a Bernoulli naive Bayes model for the bank credit data by eliminating the numeric features. Overall, this model was much better. \n",
    "4. A model skewed toward detecting bad credit cases was created using a prior distribution rather than the empirical distribution of the labels. This model correctly classified a significant number of the bad credit cases. Selecting other prior distributions will give other models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
