{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting and the AdaBoost Method\n",
    "\n",
    "Using **ensemble methods** can greatly improve the results achieved with weak machine learning algorithms, also called **weak learners**. Ensemble methods achieve better performance by aggregating the results of many statistically independent models. This process averages out the errors and produces a better, final, prediction. \n",
    "\n",
    "In this lab you will work with widely used ensemble method known as **boosting**. Boosting is a meta-algorithm since the method can be applied to many types of machine learning algorithms. In summary, boosting iteratively improves the learning of the N models by giving greater weight to training cases with larger errors. The basic boosting procedure is simple and follows these steps:\n",
    "1. N learners (machine learning models) are defined.\n",
    "2. Each of i training data cases is given an initial equal weight of 1/i.\n",
    "3. The N learners are trained on the weighted training data cases.\n",
    "4. The prediction is computed based on a aggregation of the learners; averaging over the hypothesis of the N learners. \n",
    "5. Weights for the training data cases are updated based on the aggregated errors made by the learners. Cases with larger errors are given larger weights. \n",
    "6. Steps 3, 4, and 5 are repeated until a convergence criteria is met.\n",
    "\n",
    "**Classification and regression tree models** are the weak learners most commonly used with boosting. In this lab you will work with one of the most widely used and successful boosted methods, known as **AdaBoost** or **adaptive boosting**. AdaBoost uses some large number, N, tree models. The rate at which weights are updated is **adaptive** with the errors. \n",
    "\n",
    "It is important to keep in mind that boosted machine learning is not robust to significant noise or outliers in the training data. The reweighting process gives greater weight to the large errors, and therefore can give undue weight to outliers and errors. In cases where data is noisy, the random forest algorithm may prove to be more robust. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: German Credit Dataset\n",
    "\n",
    "You will try a more complex example using the credit scoring data. You will use the prepared data which had the following preprocessing:\n",
    "1. Cleaning missing values.\n",
    "2. Aggregating categories of certain categorical variables. \n",
    "3. Encoding categorical variables as binary dummy variables.\n",
    "4. Standardizing numeric variables. \n",
    "\n",
    "As a first step, execute the code in the cell below to load the required packages to run the rest of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets ## Get dataset from sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code in the cell below to load the features and labels as numpy arrays for the example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 35)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "Features = np.array(pd.read_csv('Credit_Features.csv'))\n",
    "Labels = np.array(pd.read_csv('Credit_Labels.csv'))\n",
    "Labels = Labels.reshape(Labels.shape[0],)\n",
    "print(Features.shape)\n",
    "print(Labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested cross validation is used to estimate the optimal hyperparameters and perform model selection for the AdaBoosted tree model. Since AdaBoosted tree models are efficient to train, 10 fold cross validation is used. Execute the code in the cell below to define inside and outside fold objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below estimates the best hyperparameters using 10 fold cross validation. There are a few points to notice here:\n",
    "1. In this case, a grid of one hyperparameter is searched: \n",
    "  - learning rate shrinks the contribution of each classifier by learning_rate. There is a trade-off between learning_rate and n_estimators\n",
    "2. There is a class imbalance and a difference in the cost to the bank of misclassification of a bad credit risk customer. This will be addressed later. \n",
    "3. The model is fit on each set of hyperparameters from the grid. \n",
    "4. The best estimated hyperparameters are printed. \n",
    "\n",
    "Notice that the model uses regularization rather than feature selection. The hyperparameter search is intended to optimize the level of regularization. \n",
    "\n",
    "Execute this code, examine the result, and answer **Question 2** on the course page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {\"learning_rate\": [0.1, 1, 10]}\n",
    "## Define the AdaBoosted tree model\n",
    "nr.seed(3456)\n",
    "ab_clf = AdaBoostClassifier()  \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "nr.seed(4455)\n",
    "ab_clf = ms.GridSearchCV(estimator = ab_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "ab_clf.fit(Features, Labels)\n",
    "print(ab_clf.best_estimator_.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will run the code in the cell below to perform the outer cross validation of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance metric = 0.758\n",
      "SDT of the metric       = 0.034\n",
      "Outcomes by cv fold\n",
      "Fold  1    0.765\n",
      "Fold  2    0.721\n",
      "Fold  3    0.704\n",
      "Fold  4    0.736\n",
      "Fold  5    0.788\n",
      "Fold  6    0.772\n",
      "Fold  7    0.728\n",
      "Fold  8    0.827\n",
      "Fold  9    0.765\n",
      "Fold 10    0.771\n"
     ]
    }
   ],
   "source": [
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(ab_clf, Features, Labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these results. Notice that the standard deviation of the mean of the AUC is more than an order of magnitude smaller than the mean. This indicates that this model is likely to generalize well. \n",
    "\n",
    "Now, you will build and test a model using the estimated optimal hyperparameters. As a first step, execute the code in the cell below to create training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly sample cases to create independent training and test data\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "X_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "X_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below defines an AdaBoosted tree model object using the estimated optimal model hyperparameters and then fits the model to the training data. Execute this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr.seed(1115)\n",
    "ab_mod = AdaBoostClassifier(learning_rate = ab_clf.best_estimator_.learning_rate) \n",
    "ab_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the hyperparameters of the AdaBoosted tree model object reflect those specified. \n",
    "\n",
    "The code in the cell below scores and prints evaluation metrics for the model, using the test data subset. Execute this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive       176                36\n",
      "Actual negative        45                43\n",
      "\n",
      "Accuracy        0.73\n",
      "AUC             0.76\n",
      "Macro precision 0.67\n",
      "Macro recall    0.66\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      212            88\n",
      "Precision    0.80          0.54\n",
      "Recall       0.83          0.49\n",
      "F1           0.81          0.51\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = ab_mod.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, these performance metrics are poor. The majority of negative cases have been misclassified as positive. Adaboosted methods are sensitive to class imbalance. \n",
    "\n",
    "It is likely that the poor performance arises from the class imbalance. Notice that there is no way to reweight classes with boosting methods. Some alternatives are:\n",
    "1. **Impute** new values using a statistical algorithm. \n",
    "2. **Undersample** the majority cases. For this method a number of the cases equal to the minority case are Bernoulli sampled from the majority case. \n",
    "3. **Oversample** the minority cases. For this method the number of minority cases are resampled until they equal the number of majority cases.\n",
    "\n",
    "The code in the cell below undersamples the majority cases; good credit customers. The `choice` function from the numpy.random package is used to randomize the undersampling. The count of unique label values and the shape of the resulting arrays is printed. Execute this code to create a data set with balanced cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300 300]\n",
      "(600, 35)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "temp_Labels_1 = Labels[Labels == 1]  # Save these\n",
    "temp_Features_1 = Features[Labels == 1,:] # Save these\n",
    "temp_Labels_0 = Labels[Labels == 0]  # Undersample these\n",
    "temp_Features_0 = Features[Labels == 0,:] # Undersample these\n",
    "\n",
    "indx = nr.choice(temp_Features_0.shape[0], temp_Features_1.shape[0], replace=True)\n",
    "\n",
    "temp_Features = np.concatenate((temp_Features_1, temp_Features_0[indx,:]), axis = 0)\n",
    "temp_Labels = np.concatenate((temp_Labels_1, temp_Labels_0[indx,]), axis = 0) \n",
    "\n",
    "print(np.bincount(temp_Labels))\n",
    "print(temp_Features.shape)\n",
    "print(temp_Labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now 300 of each label case with 600 cases overall. The question is, will using these data produce better results?\n",
    "\n",
    "You will perform model selection and evaluation using nested cross validation. The code in the cell below finds the optimal learning rate parameter using cross validation. \n",
    "\n",
    "Once you have executed the code, answer **Question 3** on the course page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "nr.seed(1234)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(3214)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "## Define the AdaBoosted tree model\n",
    "nr.seed(3456)\n",
    "ab_clf = AdaBoostClassifier()  \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "nr.seed(4455)\n",
    "ab_clf = ms.GridSearchCV(estimator = ab_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "ab_clf.fit(temp_Features, temp_Labels)\n",
    "print(ab_clf.best_estimator_.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the estimated optimal learning rate parameter is smaller than before.\n",
    "\n",
    "Now, run the code in the cell below to execute the outer loop of the cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance metric = 0.758\n",
      "SDT of the metric       = 0.034\n",
      "Outcomes by cv fold\n",
      "Fold  1    0.765\n",
      "Fold  2    0.721\n",
      "Fold  3    0.704\n",
      "Fold  4    0.736\n",
      "Fold  5    0.788\n",
      "Fold  6    0.772\n",
      "Fold  7    0.728\n",
      "Fold  8    0.827\n",
      "Fold  9    0.765\n",
      "Fold 10    0.771\n"
     ]
    }
   ],
   "source": [
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(ab_clf, Features, Labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average AUC is improved compared to the imbalanced training cases. However, the differences are just within 1 standard deviation. Still, there is a reasonable chance the new results represent an improvement. \n",
    "\n",
    "Finally, you will train and evaluate a model with the balanced cases and the update hyperparameter. The code in the cell below does the following processing:\n",
    "1. Creates Bernoulli sampled test and training subsets. \n",
    "2. Defines an AdaBoosted model.\n",
    "3. Trains the AdaBoosted model.\n",
    "\n",
    "Execute this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212 212]\n",
      "(424, 35)\n",
      "(424,)\n"
     ]
    }
   ],
   "source": [
    "## Randomly sample cases to create independent training and test data\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "X_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "X_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])\n",
    "\n",
    "## Undersample the majority case for the training data\n",
    "temp_Labels_1 = y_train[y_train == 1]  # Save these\n",
    "temp_Features_1 = X_train[y_train == 1,:] # Save these\n",
    "temp_Labels_0 = y_train[y_train == 0]  # Undersample these\n",
    "temp_Features_0 = X_train[y_train == 0,:] # Undersample these\n",
    "\n",
    "indx = nr.choice(temp_Features_0.shape[0], temp_Features_1.shape[0], replace=True)\n",
    "\n",
    "X_train = np.concatenate((temp_Features_1, temp_Features_0[indx,:]), axis = 0)\n",
    "y_train = np.concatenate((temp_Labels_1, temp_Labels_0[indx,]), axis = 0) \n",
    "\n",
    "print(np.bincount(y_train))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.1,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define and fit the model\n",
    "nr.seed(1115)\n",
    "ab_mod = AdaBoostClassifier(learning_rate = ab_clf.best_estimator_.learning_rate) \n",
    "ab_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the code in the cell below to score and evaluate the model.\n",
    "\n",
    "Once you have executed the code, answer **Question 4** on the course page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive       146                66\n",
      "Actual negative        19                69\n",
      "\n",
      "Accuracy        0.72\n",
      "AUC             0.79\n",
      "Macro precision 0.70\n",
      "Macro recall    0.74\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      212            88\n",
      "Precision    0.88          0.51\n",
      "Recall       0.69          0.78\n",
      "F1           0.77          0.62\n"
     ]
    }
   ],
   "source": [
    "probabilities = ab_mod.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are significantly better than those obtained with the imbalanced training data in classifying the negative cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab you have accomplished the following:\n",
    "1. Used an AdaBoosted tree model to classify the cases of the iris data. This model produced quite good results.\n",
    "2. Applied feature importance was used for feature selection with the iris data. The model created and evaluated with the reduced feature set had essentially the same performance as the model with more features.  \n",
    "3. Used 10 fold to find estimated optimal hyperparameters for an AdaBoosted tree model to classify credit risk cases. The model did not generalize well.\n",
    "4. Applied undersampling of the majority cases to create a balanced training dataset and retrained and evaluated the model. The model created with balanced training data was significantly better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
